{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "415cf6fd-df8a-44f6-9f39-8761a0f466b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla\n"
     ]
    }
   ],
   "source": [
    "print ('bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bb7d3900-3068-4be2-9591-e0f6979fb85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20f6eb07-7c97-4bf0-bea5-8378cd4a958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "from os import path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d10544da-eede-46fd-8865-f97a0e66ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=5 # nombre de bras\n",
    "recompense_centre=5 # récompense moyenne\n",
    "dispersion_recompense=4 # écart par rapport à la moyenne\n",
    "dispersion_resultat_par_bras=2.0 # facteur pour l`écart type appliqué à chaque bras lors des tirages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f852f057-bba2-4f69-8c4c-d8d8ffb4fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "recompense_moyenne_bras = np.random.random(K)*dispersion_recompense+5\n",
    "ecart_type_bras = (np.random.random(K)+0.5)*dispersion_resultat_par_bras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14443d0d-4e85-48f7-97ef-39fde76efc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.49816048, 8.80285723, 7.92797577, 7.39463394, 5.62407456])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recompense_moyenne_bras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4798c56d-e06f-41b9-8de4-038c15b923a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordre des bras décroissant [1 2 3 0 4]\n"
     ]
    }
   ],
   "source": [
    "reference = np.flip(np.argsort(recompense_moyenne_bras))\n",
    "print(f\"Ordre des bras décroissant {reference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828bb5a9-c8ef-4c42-a52b-7ff86150ebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31198904, 1.11616722, 2.73235229, 2.20223002, 2.41614516])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecart_type_bras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e854a9da-2972-4066-94ab-37f84599f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "tirage=10000\n",
    "sample = np.zeros((tirage,K))\n",
    "for i in range(K):\n",
    "    for j in range(tirage):\n",
    "        sample[j,i]=np.random.normal(recompense_moyenne_bras[i],ecart_type_bras[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef6c905a-34a3-40ad-ac21-98a1f5a4fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sbn.boxplot(sample)\n",
    "plt.xlabel(\"Bras\")\n",
    "plt.ylabel(\"Récompense\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45157d83-e990-4a61-9c16-b156eb6cd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tirage(bras):\n",
    "    # tirage pour un bras\n",
    "    # entrée : numéro du bras\n",
    "    # sortie : récompense pour un tirage\n",
    "    return np.random.normal(recompense_moyenne_bras[bras],ecart_type_bras[bras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c281b63-b10e-4eb8-b46e-e9dd8a9aab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrire une fonction qui renvoie les numéros de bras alternativement\n",
    "# exemple 0 -> 1 -> 2 -> 3 -> 4 -> 0 ......\n",
    "# c'est ici une politique, brute mais une politique néanmoins :)\n",
    "\n",
    "def RoundRobinPolicy(action_passee,K):\n",
    "    # Round robin policy : tire un bras l'un après l'autre\n",
    "    # input : action= derniere action jouée, K nombre de bras\n",
    "    # output : nouvelle action proposée\n",
    "\n",
    "    # VOTRE CODE - 1 ligne\n",
    "    action_futur = (action_passee +1) % K\n",
    "    \n",
    "    ## print('action_passe: ', action_passee)\n",
    "    ## print('K: ', K)\n",
    "    ## print ('modulo: ', (action_passee +1) % K)\n",
    "    ## print ('action_futur: ', action_futur)\n",
    "    \n",
    "    return action_futur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b249a52-6a21-4ae3-a1ad-cd7996f16c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert RoundRobinPolicy(1,2) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd6e08bb-2d99-46e8-9e8f-c76a83ae3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "nombre_tirage=100\n",
    "\n",
    "# Nous allons stocker les résultats pour chaque bras\n",
    "Q = np.zeros((K)) # permet de stocket le cumul des récompenses\n",
    "N = np.zeros((K)) # permet de stocker le nombre de fois qu'un bras est tiré\n",
    "\n",
    "# conserver cet appel pour la suite pour comparer les résultats\n",
    "# nombre de bras , valeur initial de la moyenne des récompenses, nom de la politique\n",
    "result = []\n",
    "action = K-1 # a changer en fonction de votre implémentation. Ma politique renvoie l'action suivante, donc RoundRobinPolicy(K-1,K) va renvoyer l'action 0\n",
    "\n",
    "for i in range(nombre_tirage):\n",
    "    action = RoundRobinPolicy(i, K)\n",
    "    reward = tirage(action)\n",
    "    result.append( reward )\n",
    "    Q[ action ] += reward \n",
    "    N[ action ] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "290fceef-a466-4730-8649-218f9f1ffbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_round_robin = np.cumsum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf1575d7-dcf0-4dbb-b4cc-c2cb1a397700",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(result_round_robin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d74b5",
   "metadata": {},
   "source": [
    "# Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b689170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedyPolicy(num_action, mean_reward_per_arm):\n",
    "    # purpose : choisi le bras qui rapporte le plus\n",
    "    # input : nombre de bras, moyenne de résultat connu par bras.\n",
    "    # output : bras choisi\n",
    "\n",
    "    ## votre code\n",
    "    #action = mean_reward_per_arm.index(max(mean_reward_per_arm))\n",
    "    action = np.argmax(mean_reward_per_arm)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e22b9597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedyPolicy(5, np.array([0,1,1,0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e22672b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/xpython_6748/3731277505.py:18: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  print(f\"bras={action}, recompense(int{reward}), moyenne={np.round(Q/N+1)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bras=0, recompense(int7.431868347630945), moyenne=[18. inf inf inf inf]\n",
      "bras=1, recompense(int8.440677752859905), moyenne=[18. 19. inf inf inf]\n",
      "bras=2, recompense(int5.190512231866764), moyenne=[18. 19. 16. inf inf]\n",
      "bras=3, recompense(int7.914912528474073), moyenne=[18. 19. 16. 18. inf]\n",
      "bras=4, recompense(int5.377241556129524), moyenne=[18. 19. 16. 18. 16.]\n",
      "bras=1, recompense(int7.528983803750662), moyenne=[18. 14. 16. 18. 16.]\n",
      "bras=0, recompense(int9.980713711235706), moyenne=[14. 14. 16. 18. 16.]\n",
      "bras=0, recompense(int8.388218701228725), moyenne=[12. 14. 16. 18. 16.]\n",
      "bras=0, recompense(int6.6279191702170515), moyenne=[11. 14. 16. 18. 16.]\n",
      "bras=3, recompense(int0.5203021099170826), moyenne=[11. 14. 16. 10. 16.]\n",
      "bras=1, recompense(int7.601279048756534), moyenne=[11. 12. 16. 10. 16.]\n",
      "bras=0, recompense(int6.070869316140063), moyenne=[10. 12. 16. 10. 16.]\n",
      "bras=1, recompense(int7.647068436134308), moyenne=[10. 11. 16. 10. 16.]\n",
      "bras=1, recompense(int8.327012391522507), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int7.653917774159973), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int8.220469960290366), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int8.330989084800143), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int8.692084130688553), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int7.262258470023123), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int9.139831253877043), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int7.649187538431332), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.1261759092184285), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.263000289865576), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=0, recompense(int6.229917995841609), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.519576042505914), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.60063503620621), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.664258346008353), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.630521434047608), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.281513969166479), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.29317465466564), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.180177113074683), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.837633062963219), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.132345892811578), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.106563835338585), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int11.143827324190237), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.799105627747199), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int10.584804468666107), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int8.089891950698174), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int7.538187023936757), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.53572921539261), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int9.46785485923262), moyenne=[10. 10. 16. 10. 16.]\n",
      "bras=1, recompense(int7.897512061828173), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.467410275899807), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.928390434027953), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.588732544305364), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int6.808177695262474), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.183044752639244), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.4037401004503565), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.216718577381673), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.31099655129219), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int6.253843681694885), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.80193973270442), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int11.480403973265059), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int5.919680243736292), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.266162327893692), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.039896199718798), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.864514848736011), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.618121059350534), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int6.494165354737007), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.308189370465138), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.859928670406013), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.537141621799288), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.570684417381258), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.250779720390263), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.007304530084175), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.182250460619716), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.477159511183265), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.836333819119952), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.833573061423482), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.477408712447858), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.616045837210873), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.326224109561968), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.301528022043103), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.176927048038472), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.884822166700909), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.843638390049746), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int11.517176731440756), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.274548088509889), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.860982107838304), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.555557034290187), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.17913643660271), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.180950617239539), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.862171779338649), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.979078251208467), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.067844071572562), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.86157042487613), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.718570506393489), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.097818635376036), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int7.245402837894099), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.59356759077284), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.654220305591096), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.212820825917001), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.159020597205346), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.338526133241665), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.649337671513019), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int10.24827979953254), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int9.383921577756674), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.58601563805817), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int8.372471262361149), moyenne=[10.  9. 16. 10. 16.]\n",
      "bras=1, recompense(int5.380929288658652), moyenne=[10.  9. 16. 10. 16.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2023)\n",
    "num_action = nombre_tirage\n",
    "nombre_tirage=100\n",
    "\n",
    "#Q=  [100] * num_action\n",
    "#N= [0]* num_action\n",
    "\n",
    "Q = np.full((K), 10)\n",
    "N = np.zeros((K))\n",
    "\n",
    "result = []\n",
    "for i in range(nombre_tirage):\n",
    "    action= greedyPolicy(K, Q/(N+1))\n",
    "    reward= tirage(action)\n",
    "    result.append(reward)\n",
    "    Q[action] += reward\n",
    "    N[action] +=1\n",
    "    print(f\"bras={action}, recompense(int{reward}), moyenne={np.round(Q/N+1)}\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "398bdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocker le résultat dans un tableau avec cumul\n",
    "result_greedy_10 = np.cumsum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78ea227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer les courbes round robin et greedy optimiste\n",
    "plt.figure()\n",
    "plt.plot(result_round_robin, label='Greedy optimistic')\n",
    "plt.plot(result_greedy_10, label='Greedy optimistic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc368838",
   "metadata": {},
   "source": [
    "# E-Greedy (epslon gredy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8702b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def egreedyPolicy(num_action,epsilon,mean_reward_per_arm):\n",
    "\n",
    "    # votre code\n",
    "    # vous allez tirer un nombre aléatoire (uniforme)si celui est < epsilon, vous allez choisir une action au hasard, sinon \n",
    "    # vous choisissez la meilleur action connu.\n",
    "    \n",
    "    # Generate a random number to decide between exploration or exploitation\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        # Exploration: choose a random action\n",
    "        #print (' random < epsilon')\n",
    "        action = np.random.choice(num_action)\n",
    "    else:\n",
    "        # Exploitation: choose the greedy action (the action with the highest mean reward)\n",
    "        #print (' random >= epsilon')\n",
    "        action = np.argmax(mean_reward_per_arm)\n",
    "    \n",
    "    #print(f\"action {action}\")\n",
    "    return(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36c9dc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egreedyPolicy(3,0, [0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc23c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert egreedyPolicy(3,0,[ 0,1,0]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0af900d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "nombre_tirage=100\n",
    "epsilon=0.5\n",
    "\n",
    "result=[]\n",
    "\n",
    "for i in range(nombre_tirage):\n",
    "    action= egreedyPolicy(K, epsilon, Q)\n",
    "    reward =  tirage(action)\n",
    "    result.append(reward)\n",
    "    \n",
    "    # Update N (number of pulls for this action)\n",
    "    N[action] += 1\n",
    "    \n",
    "    # Update Q (mean reward estimate for the chosen action)\n",
    "    Q[action] = Q[action] + (1 / N[action]) * (reward - Q[action])\n",
    "    \n",
    "    #print(f\"bras={action}, recompense(int{reward}), moyenne={np.round(Q/N+1)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6af2047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocker le résultat dans un tableau avec cumul\n",
    "result_epsilongreedy = np.cumsum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb3b82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer les courbes round robin et greedy optimiste\n",
    "plt.figure()\n",
    "plt.plot(result_round_robin, label='Round Robin')\n",
    "plt.plot(result_greedy_10, label='Greedy optimistic')\n",
    "plt.plot(result_epsilongreedy, label='Epsilon Greedy ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8b997",
   "metadata": {},
   "source": [
    "# Epsilon Greedy dDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f893d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(2023)\n",
    "nombre_tirage = 100  # Total number of iterations\n",
    "K = 10  # Number of arms\n",
    "epsilonMax = 0.90  # Starting epsilon (high exploration)\n",
    "epsilonMin = 0.05  # Minimum epsilon (low exploration)\n",
    "NbPas = 80        # Number of steps for epsilon decay\n",
    "\n",
    "result = []\n",
    "eps = []  # To store epsilon values over time\n",
    "Q = np.zeros(K)  # Mean reward estimates for each arm (initialize to 0)\n",
    "N = np.zeros(K)  # Number of times each arm is selected (initialize to 0)\n",
    "\n",
    "epsilon = epsilonMax  # Initialize epsilon to maximum value\n",
    "\n",
    "for i in range(nombre_tirage):\n",
    "    action= egreedyPolicy(K, epsilon, Q)\n",
    "    \n",
    "    # Simulate reward for the chosen action (you can modify this logic as needed)\n",
    "    reward = np.random.randn() + (action + 1)  # Simulated reward\n",
    "    \n",
    "    # Update the total reward for the chosen action\n",
    "    result.append(reward)\n",
    "    \n",
    "    # Update Q (mean reward estimate for the chosen action) using incremental formula\n",
    "    N[action] += 1\n",
    "    Q[action] = Q[action] + (1 / N[action]) * (reward - Q[action])\n",
    "    \n",
    "    # Adjust epsilon with linear decay\n",
    "    epsilon = max(epsilonMin, epsilonMax - (i / NbPas) * (epsilonMax - epsilonMin))\n",
    "    eps.append(epsilon)\n",
    "\n",
    "# At the end of the loop:\n",
    "# - 'result' contains the rewards collected over time\n",
    "# - 'eps' contains the epsilon values over time (showing the decay)\n",
    "# - 'Q' contains the final reward estimates for each arm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19f047f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps [0.9, 0.889375, 0.87875, 0.868125, 0.8575, 0.846875, 0.83625, 0.825625, 0.8150000000000001, 0.8043750000000001, 0.7937500000000001, 0.7831250000000001, 0.7725, 0.7618750000000001, 0.75125, 0.7406250000000001, 0.73, 0.7193750000000001, 0.70875, 0.698125, 0.6875, 0.676875, 0.66625, 0.655625, 0.645, 0.634375, 0.62375, 0.613125, 0.6025, 0.591875, 0.58125, 0.570625, 0.56, 0.5493750000000001, 0.5387500000000001, 0.528125, 0.5175000000000001, 0.506875, 0.49625, 0.48562500000000003, 0.47500000000000003, 0.4643750000000001, 0.45375000000000004, 0.44312500000000005, 0.4325, 0.42187500000000006, 0.41125000000000006, 0.400625, 0.39, 0.379375, 0.36875, 0.358125, 0.34750000000000003, 0.33687500000000004, 0.32625000000000004, 0.31562500000000004, 0.30500000000000005, 0.29437500000000005, 0.28375000000000006, 0.27312499999999995, 0.26250000000000007, 0.25187500000000007, 0.24125000000000008, 0.23062500000000008, 0.21999999999999997, 0.2093750000000001, 0.1987500000000001, 0.188125, 0.1775000000000001, 0.166875, 0.15625, 0.14562500000000012, 0.135, 0.12437500000000001, 0.11375000000000002, 0.10312500000000002, 0.09250000000000003, 0.08187500000000003, 0.07125000000000004, 0.06062500000000004, 0.050000000000000044, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n"
     ]
    }
   ],
   "source": [
    "print(f'eps {eps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "266c9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_epsilongreedy_decay = np.cumsum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16795d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer les courbes round robin et greedy optimiste\n",
    "plt.figure()\n",
    "plt.plot(result_round_robin, label='Round Robin')\n",
    "plt.plot(result_greedy_10, label='Greedy optimistic')\n",
    "plt.plot(result_epsilongreedy, label='Epsilon Greedy ')\n",
    "plt.plot(result_epsilongreedy_decay, label='Epsilon Greedy Decay')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e160e",
   "metadata": {},
   "source": [
    "# LinUCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d48fa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linUCBPolicy(mean_reward_arm, arm_usage, c, num_tirage):\n",
    "    num_arms = len(mean_reward_arm)\n",
    "    ucb_values = np.zeros(num_arms)\n",
    "    \n",
    "    print (f'num_arms {num_arms}')\n",
    "    print(f'arm_usage {len(arm_usage)}')\n",
    "    \n",
    "    for a in range(num_arms):\n",
    "        print('----------')\n",
    "        print(f'iter {a}: ')\n",
    "        # If the arm has been used, calculate the exploration term\n",
    "        if arm_usage[a] > 0:\n",
    "            print(f'arm {a} has already been used')\n",
    "            exploration_term = np.sqrt((np.log(num_tirage + 1)) / (1 + arm_usage[a]))\n",
    "        else:\n",
    "            # Encourage exploration with a large finite value instead of 'inf'\n",
    "            print(f'arm {a} has not yet been used')\n",
    "            exploration_term = float('inf')  # A large number to encourage exploration\n",
    "        \n",
    "        # Calculate the UCB value\n",
    "        ucb_values[a] = mean_reward_arm[a] + c * exploration_term\n",
    "        \n",
    "    # Select the arm with the highest UCB value (valid index)\n",
    "    action = np.argmax(ucb_values)\n",
    "    \n",
    "    print(f'ucb_values: {ucb_values}')\n",
    "    \n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "40bd1960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_arms 3\n",
      "arm_usage 3\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "ucb_values: [1.71233448 1.72609388 1.80739308]\n",
      "Chosen arm: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the current state of the bandit problem\n",
    "mean_reward_arm = np.array([1.0, 1.2, 0.8])  # Estimated mean rewards for 3 arms\n",
    "arm_usage = np.array([5, 10, 2])  # Number of times each arm has been used\n",
    "c = 1.0  # Exploration parameter\n",
    "num_tirage = 20  # We are at the 20th pull (num_tirage)\n",
    "\n",
    "# Call the linUCBPolicy function\n",
    "chosen_arm = linUCBPolicy(mean_reward_arm, arm_usage, c, num_tirage)\n",
    "\n",
    "# Output the selected arm\n",
    "print(\"Chosen arm:\", chosen_arm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d6cbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11fc83b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a5fdc550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has not yet been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has not yet been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has not yet been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has not yet been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has not yet been used\n",
      "ucb_values: [inf inf inf inf inf]\n",
      "i 0,  action: 0, reward: -0.5102784754357179\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has not yet been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has not yet been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has not yet been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has not yet been used\n",
      "ucb_values: [0.03720386        inf        inf        inf        inf]\n",
      "i 1,  action: 1, reward: 0.05803959145887493\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has not yet been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has not yet been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has not yet been used\n",
      "ucb_values: [0.03720386 0.60552193        inf        inf        inf]\n",
      "i 2,  action: 2, reward: 0.574625680567072\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has not yet been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has not yet been used\n",
      "ucb_values: [0.03720386 0.60552193 1.12210802        inf        inf]\n",
      "i 3,  action: 3, reward: 3.887119679920439\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has already been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has not yet been used\n",
      "ucb_values: [0.03720386 0.60552193 1.12210802 4.43460202        inf]\n",
      "i 4,  action: 4, reward: -4.837443509172145\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has already been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has already been used\n",
      "ucb_values: [ 0.03720386  0.60552193  1.12210802  4.43460202 -4.28996117]\n",
      "i 5,  action: 3, reward: 8.441789915680262\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has already been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has already been used\n",
      "ucb_values: [ 0.03720386  0.60552193  1.12210802  6.61147225 -4.28996117]\n",
      "i 6,  action: 3, reward: 0.6716736706858795\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has already been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has already been used\n",
      "ucb_values: [ 0.03720386  0.60552193  1.12210802  4.72065623 -4.28996117]\n",
      "i 7,  action: 3, reward: 4.405472919271579\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has already been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has already been used\n",
      "ucb_values: [ 0.03720386  0.60552193  1.12210802  4.69777228 -4.28996117]\n",
      "i 8,  action: 3, reward: 3.4785779514819533\n",
      "num_arms 5\n",
      "arm_usage 5\n",
      "----------\n",
      "iter 0: \n",
      "arm 0 has already been used\n",
      "----------\n",
      "iter 1: \n",
      "arm 1 has already been used\n",
      "----------\n",
      "iter 2: \n",
      "arm 2 has already been used\n",
      "----------\n",
      "iter 3: \n",
      "arm 3 has already been used\n",
      "----------\n",
      "iter 4: \n",
      "arm 4 has already been used\n",
      "ucb_values: [ 0.03720386  0.60552193  1.12210802  4.4930159  -4.28996117]\n",
      "i 9,  action: 3, reward: 1.9882139785776718\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2023)\n",
    "nombre_tirage=10\n",
    "\n",
    "Q = np.zeros((K))  # Estimated total rewards\n",
    "N = np.zeros((K))  # Number of times each arm has been used\n",
    "\n",
    "result=[]\n",
    "c=0.5\n",
    "\n",
    "# Initialize with small random values for better differentiation\n",
    "mean_reward_arm = np.random.rand(K) * 0.1  \n",
    "recompense_moyenne_bras = mean_reward_arm\n",
    "\n",
    "num_tirage = nombre_tirage\n",
    "arm_usage = np.zeros(K)\n",
    "\n",
    "for i in range(nombre_tirage):\n",
    "    action=  chosen_arm = linUCBPolicy(mean_reward_arm, arm_usage, c, num_tirage)\n",
    "    reward = tirage(action)\n",
    "    print(f'i {i},  action: {action}, reward: {reward}')\n",
    "    Q[action] += reward\n",
    "    N[action] += 1\n",
    "    \n",
    "    arm_usage[action] += 1  # Update usage count for the chosen arm\n",
    "    \n",
    "    # Update the mean reward for the chosen arm\n",
    "    if N[action] > 0:\n",
    "        mean_reward_arm[action] = Q[action] / N[action]\n",
    "        \n",
    "    result.append(reward)   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "412cf6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lin_ucb = np.cumsum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cfb686f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparer les courbes round robin et greedy optimiste\n",
    "plt.figure()\n",
    "plt.plot(result_round_robin, label='Round Robin')\n",
    "plt.plot(result_greedy_10, label='Greedy optimistic')\n",
    "plt.plot(result_epsilongreedy, label='Epsilon Greedy ')\n",
    "plt.plot(result_epsilongreedy_decay, label='Epsilon Greedy Decay')\n",
    "plt.plot(result_lin_ucb, label='LinUCB')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
